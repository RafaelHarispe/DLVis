{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "\n",
      "scoress Max1: [[ 1.3 -0.1  0.6]\n",
      " [ 1.4  0.9  1.6]\n",
      " [ 1.9 -2.1 -0.4]\n",
      " [ 0.2 -1.5 -2. ]\n",
      " [ 1.1 -2.9 -2.1]\n",
      " [-1.4  1.7 -1.2]] Max [ 1.3  1.6  1.9  0.2  1.1  1.7]\n",
      "\n",
      "scoress Max2: [[ 1.3 -0.1  0.6]\n",
      " [ 1.4  0.9  1.6]\n",
      " [ 1.9 -2.1 -0.4]\n",
      " [ 0.2 -1.5 -2. ]\n",
      " [ 1.1 -2.9 -2.1]\n",
      " [-1.4  1.7 -1.2]] Max [[ 1.3]\n",
      " [ 1.6]\n",
      " [ 1.9]\n",
      " [ 0.2]\n",
      " [ 1.1]\n",
      " [ 1.7]]\n",
      "scores restados: [[ 0.  -1.4 -0.7]\n",
      " [-0.2 -0.7  0. ]\n",
      " [ 0.  -4.  -2.3]\n",
      " [ 0.  -1.7 -2.2]\n",
      " [ 0.  -4.  -3.2]\n",
      " [-3.1  0.  -2.9]]\n",
      "scores restados: [[ 0.  -1.4 -0.7]\n",
      " [-0.2 -0.7  0. ]\n",
      " [ 0.  -4.  -2.3]\n",
      " [ 0.  -1.7 -2.2]\n",
      " [ 0.  -4.  -3.2]\n",
      " [-3.1  0.  -2.9]]\n",
      "exponencial scores [[ 3.66929667  0.90483742  1.8221188 ]\n",
      " [ 4.05519997  2.45960311  4.95303242]\n",
      " [ 6.68589444  0.12245643  0.67032005]\n",
      " [ 1.22140276  0.22313016  0.13533528]\n",
      " [ 3.00416602  0.05502322  0.12245643]\n",
      " [ 0.24659696  5.47394739  0.30119421]]\n",
      "suma exponencial [  6.39625289  11.4678355    7.47867092   1.5798682    3.18164567\n",
      "   6.02173857]\n",
      "q [[ 0.57366348  0.14146367  0.28487285]\n",
      " [ 0.35361511  0.21447841  0.43190648]\n",
      " [ 0.893995    0.01637409  0.08963091]\n",
      " [ 0.77310421  0.1412334   0.08566239]\n",
      " [ 0.94421766  0.01729395  0.03848839]\n",
      " [ 0.04095112  0.90903106  0.05001782]]\n",
      "log loss  [ 0.55571233  1.0395462   0.11205509  1.95734143  4.05739857  2.99537602]\n",
      "loss i [ 0.55571233  1.0395462   0.11205509  1.95734143  4.05739857  2.99537602]\n"
     ]
    }
   ],
   "source": [
    "#W = np.random.random(2 , 3) * 0.0001 \n",
    "\n",
    "W = np.array([[1,2,0], [2,-4,0.5], [3,-1,-0.5]])\n",
    "X = np.array([[0.5,0.4], [0.8,0.3], [0.3,0.8], [-0.4,0.3],[-0.3,0.7],[-0.4,-0.5]])\n",
    "X = np.hstack([X, np.ones((X.shape[0],1))])\n",
    "W = W.T\n",
    "\n",
    "scoress = X.dot(W)\n",
    "\n",
    "\"\"\"scores = X[0].dot(W)\n",
    "print(\"scores:\",scores)\n",
    "scores -=  np.max(scores)\n",
    "print(\"scores restados:\",scores)\n",
    "print(\"exponencial scores\", np.exp(scores))\n",
    "print(\"suma exponencial\", np.sum(np.exp(scores)))\n",
    "q = np.exp(scores) / np.sum(np.exp(scores))\n",
    "print(\"q\",q)\n",
    "print(\"log q0\",-np.log(q[0]))\n",
    "\"\"\"\n",
    "print(\"---------------\")\n",
    "\n",
    "print(\"\\nscoress Max1:\",scoress, \"Max\", np.max(scoress, axis = 1))\n",
    "print(\"\\nscoress Max2:\",scoress, \"Max\", np.amax(scoress, axis =1, keepdims = True))\n",
    "\n",
    "scoressRes = np.subtract(scoress.T, np.max(scoress, axis = 1)).T\n",
    "print(\"scores restados:\",scoressRes)\n",
    "scoressRes2 = np.subtract(scoress, np.amax(scoress, axis = 1, keepdims = True))\n",
    "print(\"scores restados:\",scoressRes2)\n",
    "\n",
    "print(\"exponencial scores\", np.exp(scoress))\n",
    "print(\"suma exponencial\", np.sum(np.exp(scoress), axis = 1))\n",
    "\n",
    "q = (np.exp(scoress).T / np.sum(np.exp(scoress), axis = 1)).T\n",
    "print(\"q\",q)\n",
    "loss = -np.log(q)\n",
    "print(\"log loss \",loss[[0,1,2,3,4,5], [0,0,0,1,1,2]])\n",
    "\n",
    "print(\"loss i\",loss[[0,1,2,3,4,5], [0,0,0,1,1,2]])\n",
    "\n",
    "print(\"---------------\")\n",
    "q[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 7 0]\n",
      " [2 2 5 2]\n",
      " [3 1 6 3]]\n",
      "[[ 1.  3.  7.  0.]\n",
      " [ 2.  2.  5.  2.]\n",
      " [ 3.  1.  6.  3.]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[1,2,3],\n",
    "     [3,2,1],\n",
    "     [7,5,6],\n",
    "     [0,2,3]])\n",
    "\n",
    "q = [[1,2],\n",
    "     [0,1],\n",
    "     [8,3],\n",
    "     [2,2]]\n",
    "\n",
    "dW = np.zeros((3,4))\n",
    "\"\"\"for i on images\n",
    "    for j on classes\n",
    "        #dW[,j] += (q[i,j] - (j == y[i])) * X[i]\n",
    "        dW[,j] += (q[i,j] - (j == y[i])) * X[i]\n",
    "\"\"\"\n",
    "\n",
    "#dW[:,1] += X[2] * 2\n",
    "print(X.T)\n",
    "print(dW + X.T)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20, 10), (5,))"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "X = 10 * np.random.randn(20, 10)\n",
    "y = np.array([0, 1, 2, 2, 1])\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 6])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dscores = [[1,2],\n",
    "        [3,4]\n",
    "]\n",
    "np.sum(dscores, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [2 2]\n",
      " [3 3]]\n",
      "[[ 0.33333333  0.66666667]\n",
      " [ 1.          1.        ]\n",
      " [ 3.          3.        ]]\n",
      "[[ 0.5         0.66666667]\n",
      " [ 1.          0.66666667]\n",
      " [ 1.5         1.        ]]\n",
      "[[ 0.33333333  0.66666667]\n",
      " [ 0.66666667  0.66666667]\n",
      " [ 1.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "arr1 = np.array([[1,2],[2,2],[3,3]])\n",
    "print(arr1)\n",
    "print((arr1.T / [3,2,1]).T)\n",
    "print(arr1 / [2,3])\n",
    "print(arr1 / 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "## Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X', (5, 2), 'y', (5,), 'W1', (2, 4), 'W2', (4, 3)]"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_size = 4\n",
    "output_size = 3\n",
    "\n",
    "X = np.array([[1,2],\n",
    "              [1,-1],\n",
    "              [2,0],\n",
    "              [2,1],\n",
    "              [2,3]])\n",
    "\n",
    "y = np.array([1,2,0,0,1])\n",
    "X.shape, y. shape\n",
    "\n",
    "W1 = 1e-4 * np.random.randn(2, hidden_size)\n",
    "b1 = np.zeros(hidden_size)\n",
    "W2 = 1e-4 * np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros(output_size)\n",
    "\n",
    "\n",
    "[\"X\", X.shape, \"y\",y.shape, \"W1\",W1.shape, \"W2\",W2.shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1,  2],\n",
       "        [ 1, -1],\n",
       "        [ 2,  0],\n",
       "        [ 2,  1],\n",
       "        [ 2,  3]]),\n",
       " 'W1',\n",
       " array([[  9.66539250e-05,   7.13049050e-05,   1.30620607e-04,\n",
       "          -6.04602969e-05],\n",
       "        [  6.36583409e-05,   1.40925339e-04,   1.62091229e-04,\n",
       "          -8.06184817e-05]]),\n",
       " 'b1',\n",
       " array([ 0.,  0.,  0.,  0.]),\n",
       " 'W2',\n",
       " array([[ -2.51674208e-05,   3.82715174e-05,  -2.88997343e-05],\n",
       "        [ -3.91816240e-05,   6.84001328e-05,  -3.53409983e-05],\n",
       "        [ -1.78791289e-04,   3.61847316e-05,  -4.24492791e-05],\n",
       "        [ -7.31530982e-05,  -1.56573815e-04,   1.01382247e-04]]),\n",
       " 'b2',\n",
       " array([ 0.,  0.,  0.]))"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, \"W1\", W1, \"b1\", b1, \"W2\", W2, \"b2\", b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "### Fordward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fordward\n",
      "------\n",
      "z1 [[  2.23970607e-04   3.53155583e-04   4.54803064e-04  -2.21697260e-04]\n",
      " [  3.29955841e-05  -6.96204339e-05  -3.14706220e-05   2.01581848e-05]\n",
      " [  1.93307850e-04   1.42609810e-04   2.61241213e-04  -1.20920594e-04]\n",
      " [  2.56966191e-04   2.83535149e-04   4.23332442e-04  -2.01539076e-04]\n",
      " [  3.84282873e-04   5.65385827e-04   7.47514899e-04  -3.62776039e-04]]\n",
      "a1 [[  2.23970607e-04   3.53155583e-04   4.54803064e-04   0.00000000e+00]\n",
      " [  3.29955841e-05   0.00000000e+00   0.00000000e+00   2.01581848e-05]\n",
      " [  1.93307850e-04   1.42609810e-04   2.61241213e-04   0.00000000e+00]\n",
      " [  2.56966191e-04   2.83535149e-04   4.23332442e-04   0.00000000e+00]\n",
      " [  3.84282873e-04   5.65385827e-04   7.47514899e-04   0.00000000e+00]]\n",
      "Scores\n",
      "------\n",
      " [[ -1.00788798e-07   4.91845105e-08  -3.82596240e-08]\n",
      " [ -2.30504742e-09  -1.89345283e-09   1.09011845e-09]\n",
      " [ -5.71603972e-08   2.66056579e-08  -2.17160197e-08]\n",
      " [ -9.32646968e-08   4.45464987e-08  -3.54168268e-08]\n",
      " [ -1.65473296e-07   8.04281803e-08  -6.28184410e-08]]\n"
     ]
    }
   ],
   "source": [
    "z1 = X.dot(W1) + b1\n",
    "print(\"z1\", z1)\n",
    "a1 = np.maximum(0, z1) # funcion de activacion\n",
    "print(\"a1\", a1)\n",
    "scores = a1.dot(W2) + b2\n",
    "print(\"Scores\\n------\\n\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp scores [[ 0.9999999   1.00000005  0.99999996]\n",
      " [ 1.          1.          1.        ]\n",
      " [ 0.99999994  1.00000003  0.99999998]\n",
      " [ 0.99999991  1.00000004  0.99999996]\n",
      " [ 0.99999983  1.00000008  0.99999994]]\n",
      "suma [[ 2.99999991]\n",
      " [ 3.        ]\n",
      " [ 2.99999995]\n",
      " [ 2.99999992]\n",
      " [ 2.99999985]]\n",
      "probs [[ 0.33333331  0.33333336  0.33333333]\n",
      " [ 0.33333333  0.33333333  0.33333333]\n",
      " [ 0.33333332  0.33333335  0.33333333]\n",
      " [ 0.33333331  0.33333336  0.33333333]\n",
      " [ 0.33333329  0.33333338  0.33333333]]\n",
      "probs_select [ 0.33333336  0.33333333  0.33333332  0.33333331  0.33333338]\n",
      "corect_logprobs [ 1.09861221  1.09861229  1.09861233  1.09861235  1.09861216]\n",
      "data_loss 1.09861226746\n",
      "W1*W1 [[  9.34198122e-09   5.08438948e-09   1.70617428e-08   3.65544750e-09]\n",
      " [  4.05238437e-09   1.98599512e-08   2.62735664e-08   6.49933960e-09]]\n",
      "W2*W2 [[  6.33399068e-10   1.46470904e-09   8.35194643e-10]\n",
      " [  1.53519966e-09   4.67857817e-09   1.24898616e-09]\n",
      " [  3.19663251e-08   1.30933480e-09   1.80194129e-09]\n",
      " [  5.35137577e-09   2.45153596e-08   1.02783599e-08]]\n",
      "reg_loss 8.87237828662e-09\n"
     ]
    }
   ],
   "source": [
    "exp_scores = np.exp(scores)\n",
    "print(\"exp scores\", exp_scores)\n",
    "\n",
    "suma = np.sum(exp_scores, axis=1, keepdims=True)\n",
    "print(\"suma\", suma)\n",
    "probs = exp_scores / suma \n",
    "print(\"probs\", probs)\n",
    "probs_select = probs[range(X.shape[0]), y]\n",
    "#probs_select = [1,1,1,1,1]\n",
    "print(\"probs_select\", probs_select)\n",
    "corect_logprobs = -np.log(probs_select)\n",
    "print(\"corect_logprobs\", corect_logprobs)\n",
    "\n",
    "data_loss = np.sum(corect_logprobs) / X.shape[0]\n",
    "print(\"data_loss\", data_loss)\n",
    "\n",
    "print(\"W1*W1\", W1 * W1)\n",
    "print(\"W2*W2\", W2 * W2)\n",
    "\n",
    "reg = 0.1\n",
    "reg_loss = 0.5 * reg * np.sum(W1 * W1) + 0.5 * reg * np.sum(W2 * W2)\n",
    "print(\"reg_loss\", reg_loss)\n",
    "#loss = data_loss + reg_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "### Gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dscores [[ 0.06666666 -0.13333333  0.06666667]\n",
      " [ 0.06666667  0.06666667 -0.13333333]\n",
      " [-0.13333334  0.06666667  0.06666667]\n",
      " [-0.13333334  0.06666667  0.06666667]\n",
      " [ 0.06666666 -0.13333332  0.06666667]]\n",
      "dscores [[ 0.01333333 -0.22666667  0.01333333]\n",
      " [ 0.01333333  0.01333333 -0.22666667]\n",
      " [-0.22666667  0.01333333  0.01333333]\n",
      " [-0.22666667  0.01333333  0.01333333]\n",
      " [ 0.01333333 -0.22666666  0.01333333]]\n"
     ]
    }
   ],
   "source": [
    "print(\"dscores\", dscores)\n",
    "dscores = probs\n",
    "dscores[range(X.shape[0]),y] -= 1\n",
    "dscores /= X.shape[0]\n",
    "print(\"dscores\", dscores)\n",
    "\n",
    "# W2 and b2\n",
    "W2 = np.dot(a1.T, dscores)\n",
    "#print(a1.shape)\n",
    "b2 = np.sum(dscores, axis=0)\n",
    "# next backprop into hidden layer\n",
    "dhidden = np.dot(dscores, W2.T)\n",
    "# backprop the ReLU non-linearity\n",
    "dhidden[a1 <= 0] = 0\n",
    "# finally into W,b\n",
    "W1 = np.dot(X.T, dhidden)\n",
    "b1 = np.sum(dhidden, axis=0)\n",
    "\n",
    "# add regularization gradient contribution\n",
    "W2 += reg * W2\n",
    "W1 += reg * W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  4],\n",
       "       [ 9, 16]])"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([[1,2], [3,4]])\n",
    "arr*arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 5 is out of bounds for axis 0 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-413-9271c1067b0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Compute vector of scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mf_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Normalization trick to avoid numerical instability, per http://cs231n.github.io/linear-classify/#softmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 5 is out of bounds for axis 0 with size 5"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    # Compute vector of scores\n",
    "    f_i = X[i].dot(W)\n",
    "\n",
    "    # Normalization trick to avoid numerical instability, per http://cs231n.github.io/linear-classify/#softmax\n",
    "    #f_i -= np.max(f_i)\n",
    "\n",
    "    # Compute loss (and add to it, divided later)\n",
    "    sum_j = np.sum(np.exp(f_i))\n",
    "    p = lambda k: np.exp(f_i[k]) / sum_j\n",
    "    loss += -np.log(p(y[i]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
